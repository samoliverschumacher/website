<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Autonomous vechicle microsleep detector Vol2: Modelling - Sam Schumacher</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="Example test article that contains basic HTML elements for text formatting on the Web.">
		<meta property="og:title" content="Autonomous vechicle microsleep detector Vol2: Modelling" />
<meta property="og:description" content="Example test article that contains basic HTML elements for text formatting on the Web." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://github.com/samoliverschumacher/post/eeg_modelling/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2020-12-18T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2020-12-18T00:00:00&#43;00:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="https://github.com/samoliverschumacher/css/style.css">
	

	<link rel="shortcut icon" href="https://github.com/samoliverschumacher/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo logo--mixed">
		<a class="logo__link" href="https://github.com/samoliverschumacher/" title="Sam Schumacher" rel="home">
			<div class="logo__item logo__imagebox">
					<img class="logo__img" src="https://github.com/samoliverschumacher/images/eegeda/1.png">
				</div><div class="logo__item logo__text">
					<div class="logo__title">Sam Schumacher</div>
					<div class="logo__tagline">ML &amp; AI</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="https://github.com/samoliverschumacher/about/">
				
				<span class="menu__text">this blog</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Autonomous vechicle microsleep detector Vol2: Modelling</h1>
			<p class="post__lead">Binary classification using EEG readings (part 2 of 3)</p>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2020-12-18T00:00:00Z">December 18, 2020</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="https://github.com/samoliverschumacher/categories/machine-learning/" rel="category">Machine Learning</a>, <a class="meta__link" href="https://github.com/samoliverschumacher/categories/datascience/" rel="category">Datascience</a>
	</span>
</div></div>
		</header><div class="content post__content clearfix">
			<h2 id="autonomous-vehichles-are-no-longer-reserved-for-the-realm-of-science-fiction-but-some-ai-experts-say-the-complexities-of-ai-driven-cars-in-public-make-the-possibility-never-eeding-to-drive-a-far-off-future-perhaps-to-bridge-the-gap-are-technologies-that-greatly-reduce-the-labour-involved-in-driving-while-still-reducing-the-risk"><em>Autonomous vehichles are no longer reserved for the realm of science fiction, but some AI experts say the complexities of AI-driven cars in public make the possibility never eeding to drive a far off future. Perhaps to bridge the gap are technologies that greatly reduce the labour involved in driving, while still reducing the risk.</em></h2>
<p>Table of Contents</p>
<ul>
<li><a href="#summary-of-exploratory-data-analysis">Summary of Exploratory Data Analysis</a></li>
<li><a href="#feature-engineering-windowed-variable-correlations">Feature Engineering: Windowed Variable Correlations</a>
<ul>
<li><a href="#selecting-correlation-windows">Selecting correlation windows</a></li>
<li><a href="#normalising--transforming">Normalising &amp; Transforming</a></li>
</ul>
</li>
<li><a href="#probit-regression">Probit Regression</a>
<ul>
<li><a href="#model-evaluation">Model Evaluation</a></li>
</ul>
</li>
<li><a href="#lasso-probit-regression">Lasso Probit Regression</a>
<ul>
<li><a href="#selecting-the-best">Selecting the best</a></li>
</ul>
</li>
<li><a href="#partial-least-squares-regression">Partial Least Squares Regression</a>
<ul>
<li><a href="#reducing-dimensionality-of-the-feature-set">Reducing dimensionality of the feature set.</a></li>
<li><a href="#false-positives-vs-false-negatives-residual-skew">False positives vs. False Negatives <em>(residual skew)</em></a></li>
</ul>
</li>
<li><a href="#recurrent-neural-network---long-short-term-memory-lstm">Recurrent Neural Network - Long Short Term Memory (LSTM)</a></li>
<li><a href="#lstm-shaping-training-samples">LSTM: Shaping training samples</a>
<ul>
<li><a href="#maintaining-cell-memory-across-mini-batches">Maintaining cell-memory across mini-batches</a></li>
<li><a href="#convergence-of-lstm-with-memory-passed-through-mini-batches">Convergence of LSTM with memory passed through mini-batches;</a></li>
<li><a href="#real-world-implementation-of-a-memory-preserving-lstm">Real-world implementation of a memory preserving LSTM</a></li>
<li><a href="#defining-the-network-topology">Defining the network topology</a></li>
</ul>
</li>
<li><a href="#lstm-model-training--prediction">LSTM Model Training &amp; Prediction</a></li>
<li><a href="#lstm-model-selection">LSTM: Model Selection</a></li>
<li><a href="#summary">Summary</a>
<ul>
<li><a href="#in-sample-performance">In-sample performance</a></li>
<li><a href="#generalisation-performance">Generalisation performance</a></li>
<li><a href="#real-world-application-of-predictions">Real-world application of predictions</a></li>
</ul>
</li>
</ul>
<h1 id="summary-of-exploratory-data-analysis">Summary of Exploratory Data Analysis</h1>
<p><em><strong>Insights found in the dataset;</strong></em></p>
<ol>
<li><em>EEG values' extremes are asymmetric around their medians.</em></li>
<li><em>Mean EEG value doesn&rsquo;t change much globally with eye state.</em></li>
<li><em>Lead signals exist for eyes opening &amp; eyes 4. closing. Strongest in variables 1-2 &amp; 11-14.</em></li>
<li><em>&lsquo;Shape&rsquo; of Lead signal is independent of starting magnitude.</em></li>
<li><em>False transition signals are indicated by anomalies in EEGs 5 &amp; 8.</em></li>
<li><em>Some EEG correlations shift significatnly depending on eye state.</em></li>
</ol>
<p><em><strong>Assumptions on the modelling process</strong></em></p>
<ul>
<li>No test datasets. With only EEG sensor data from one patient across one continuous period, inferring auto-pilots performance in a real life situation is too much of a leap from the limited dataset. Knowing generalisation performance is impossible, instead we will speculate, and prescribe robust modelling techniques when they should be.</li>
<li>Applying the machine learning solution in a real world context, data will be fed to the system continuously, although a total allowable lag of 0.2 seconds will be assumed. This will cover car dynamics &amp; machine computation time while still preventing long sequences of an uncontrolled car!</li>
</ul>
<p><em><strong>Constraints to design for</strong></em></p>
<ol>
<li><em><strong>3x more &lsquo;Open eye&rsquo; misclassifications than &lsquo;Closed eye&rsquo; misclassifications.</strong></em></li>
<li><em><strong>Delay in detecting eye state change must be &lt;1 second.</strong></em></li>
<li><em><strong>Short interval eye closed (&lt;0.3 seconds), to be disregarded (blinking not the same as closing)</strong></em></li>
</ol>
<p>The variable correlation insight may allow models not traditionally used for times series prediction to be used.
The window selected must be short enough so that a few consecutive miscalssifications isn&rsquo;t catastrphoic in the business application, but long enough that it captures the predictive power of EEG correlations, instead of noise.</p>
<p>A custom built Long Short Term Memory (LSTM) recurrent neural network will be used to take advantage of the EEG patterns that mark transition points, and maintain the eye state until a new pattern signals a transition back to the original open/closed state.</p>
<p>MATLAB functions exist for many traditional time series modelling techniques, but using models that require independently drawn data (not time series) will be more interesting.</p>
<p>To approach the cost asymmetry probelm of avoiding False Negatives more than False Positives, some convex optimisation techniques will be explored where MATALAB native functions may not be satisfactory.</p>
<h1 id="feature-engineering-windowed-variable-correlations">Feature Engineering: Windowed Variable Correlations</h1>
<p>The Exploratory Data Analysis (EDA) showed that EEG correlations had some predictive power in eye state. The creation process was;</p>
<pre><code>1. Randomly sample a very small number of EEG observations, in any temporal order, stratifying the draws into open &amp; closed observations.
2. Calculate the correlations between EEGs in that sample.
3. Compare those correlations which were calculated with random observations of Open compared to Closed eye-state.
</code></pre>
<h2 id="selecting-correlation-windows">Selecting correlation windows</h2>
<p>The business application is an autonomous driving system for a passenger who&rsquo;s shut their eyes. So the model will make predictions &lsquo;on-line&rsquo;, and a lag in making that prediction greater than 0.2 seconds is too slow. A lot can happen when travelling at 100km/h.</p>
<p>Creating new features out of the raw EEG values will be through a process of shifting a &lsquo;window&rsquo; forward through time over the data. Each 0.2 seconds, correlations between EEGs are calculated over a window spanning the latest 2 seconds.</p>
<p>This will create 567 samples out of the original 14980 samples of raw data, where the first observation in the new feature set is EEG correlations during the first 256 timesteps.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% Load Data from E.D.A.</span>
load(<span style="color:#e6db74">&#39;EEGloseEyes_EDA.mat&#39;</span>,<span style="color:#e6db74">&#39;windowlength&#39;</span>,<span style="color:#e6db74">&#39;TimeSeries_cln&#39;</span>,<span style="color:#e6db74">&#39;TimeSeries_clnnorm&#39;</span>,<span style="color:#e6db74">&#39;idx_openclose&#39;</span>,<span style="color:#e6db74">&#39;N&#39;</span>,<span style="color:#e6db74">&#39;Nvars&#39;</span>,<span style="color:#e6db74">&#39;N_seconds&#39;</span>,<span style="color:#e6db74">&#39;win_trainN&#39;</span>);
<span style="color:#75715e">% Correlations between EEGs for use in a binary classifier</span>
<span style="color:#75715e">% To capture correlations between EEGs, move a</span>
<span style="color:#75715e">% window across the dataset. step length of 0.5 sec, and width of 3 sec</span>
windowlength_seconds = <span style="color:#ae81ff">2</span>;
steplength_seconds = <span style="color:#ae81ff">0.2</span>;
windowlength = round((N<span style="color:#f92672">/</span>N_seconds)<span style="color:#f92672">*</span>windowlength_seconds);
steplength = round((N<span style="color:#f92672">/</span>N_seconds)<span style="color:#f92672">*</span>steplength_seconds);
windowstartId = (<span style="color:#ae81ff">1</span>:steplength:N<span style="color:#f92672">-</span>windowlength);
<span style="color:#75715e">% vectorised EEG correlation data for model training</span>
x = NaN( numel(windowstartId) , ((Nvars^<span style="color:#ae81ff">2</span>)<span style="color:#f92672">-</span>Nvars)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span> );
<span style="color:#75715e">% target variable is avg. # of &#34;open eye&#34; observations in each window</span>
y = NaN( numel(windowstartId) , <span style="color:#ae81ff">1</span> );
<span style="color:#75715e">% store # of timesteps in each window, for observation importance weighting</span>
winlen = NaN( numel(windowstartId) , <span style="color:#ae81ff">1</span> );
<span style="color:#66d9ef">for</span> si=windowstartId
    obsind = find(windowstartId<span style="color:#f92672">==</span>si);
    <span style="color:#75715e">% correlation between EEGs in the window leading up to the prediction period</span>
    EEGcor = corr( TimeSeries_clnnorm(si: si<span style="color:#f92672">+</span>windowlength,:));
    x(obsind,:) = EEGcor(tril(ones(<span style="color:#ae81ff">14</span>),<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>);
    response_t = si<span style="color:#f92672">+</span>windowlength<span style="color:#f92672">+</span>[<span style="color:#ae81ff">1</span>:steplength];
    y(obsind,<span style="color:#ae81ff">1</span>) = sum(idx_openclose(response_t(response_t<span style="color:#f92672">&lt;</span>=N)) <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> ); <span style="color:#75715e">% total timesteps with Open eyes</span>
    winlen(obsind,<span style="color:#ae81ff">1</span>) = sum((response_t<span style="color:#f92672">&lt;</span>=N)); <span style="color:#75715e">% number of timesteps in the window.</span>
<span style="color:#66d9ef">end</span>
<span style="color:#75715e">% average eye-state for each windowed sample</span>
y_weighted = y(:,<span style="color:#ae81ff">1</span>)<span style="color:#f92672">./</span>winlen;
<span style="color:#75715e">% if dataset contained EEG timeseries from multiple patients, those would be split into train, validate &amp; test sets.</span>
<span style="color:#75715e">% split data into train-test with a ratio.</span>
trainsplit_ratio = <span style="color:#ae81ff">1.0</span>;
trainidx = <span style="color:#ae81ff">1</span>:floor(N<span style="color:#f92672">*</span>trainsplit_ratio);
<span style="color:#75715e">% train-test will not be used in this project. test = train = all data</span>
testidx = floor(N<span style="color:#f92672">*</span>trainsplit_ratio)<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>:N;
<span style="color:#75715e">% Indicies of the windowed variable correlation data.</span>
win_trainidx = <span style="color:#ae81ff">1</span>:floor( numel(windowstartId)<span style="color:#f92672">*</span>trainsplit_ratio);
x_train = x(win_trainidx,:);
y_train = y_weighted(win_trainidx,<span style="color:#ae81ff">1</span>);
<span style="color:#75715e">% convert an average number of eye-states, into either one or the other.</span>
yBinom_train = (y_train)<span style="color:#f92672">&gt;</span>=<span style="color:#ae81ff">0.5</span>;
<span style="color:#75715e">% lets take a look at the histogram of this new feature</span>
figure(<span style="color:#e6db74">&#39;Position&#39;</span>,[<span style="color:#ae81ff">612</span>   <span style="color:#ae81ff">358</span>   <span style="color:#ae81ff">945</span>   <span style="color:#ae81ff">568</span>]); 
histogram(x_train,linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">60</span>),<span style="color:#e6db74">&#39;Normalization&#39;</span>,<span style="color:#e6db74">&#39;probability&#39;</span>); title(<span style="color:#e6db74">&#39;EEG correlations histogram&#39;</span>); xlabel(<span style="color:#e6db74">&#39;x&#39;</span>,<span style="color:#e6db74">&#39;Interpreter&#39;</span>,<span style="color:#e6db74">&#39;latex&#39;</span>,<span style="color:#e6db74">&#39;FontSize&#39;</span>,<span style="color:#ae81ff">16</span>); ylabel(<span style="color:#e6db74">&#39;$P( x )$&#39;</span>,<span style="color:#e6db74">&#39;Interpreter&#39;</span>,<span style="color:#e6db74">&#39;latex&#39;</span>,<span style="color:#e6db74">&#39;FontSize&#39;</span>,<span style="color:#ae81ff">16</span>)
</code></pre></div><p><img src="../../images/eegmodelling/1.png" alt="hist eeg correlations"></p>
<h2 id="normalising--transforming">Normalising &amp; Transforming</h2>
<p>This feature is heavily skewed to the right, so a transform will be needed to normalise it. Normalised features will mean that marginal changes in them (X), will equate to the same percentage change in the predicted Y variable once multiplied by a coefficient, no matter the value of X.<br>
An exponential transform would work, as we want to spread out the upper values which currently are clumped together a little. Centering the data and then using its Z-scores should spread values evenly further.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">hold on; 
xLog_train = exp(x_train);
<span style="color:#75715e">% z-score of data  its exponent</span>
xNorm_train = normalize(x_train,<span style="color:#ae81ff">1</span>);
xLogNorm_train = normalize( exp(x_train) ,<span style="color:#ae81ff">1</span>);
histogram( xLog_train ,linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">60</span>) ,<span style="color:#e6db74">&#39;Normalization&#39;</span>,<span style="color:#e6db74">&#39;probability&#39;</span>); 
histogram( xNorm_train ,linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">60</span>) ,<span style="color:#e6db74">&#39;Normalization&#39;</span>,<span style="color:#e6db74">&#39;probability&#39;</span>); 
histogram( xLogNorm_train ,linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">60</span>) ,<span style="color:#e6db74">&#39;Normalization&#39;</span>,<span style="color:#e6db74">&#39;probability&#39;</span>,<span style="color:#e6db74">&#39;FaceColor&#39;</span>,<span style="color:#e6db74">&#39;none&#39;</span>,<span style="color:#e6db74">&#39;LineWidth&#39;</span>,<span style="color:#ae81ff">1</span>); 
legend({<span style="color:#e6db74">&#39;EEG Correlations&#39;</span>,<span style="color:#e6db74">&#39;exp( EEG corr )&#39;</span>,<span style="color:#e6db74">&#39;Std Norm EEG corr&#39;</span>,<span style="color:#e6db74">&#39;Std Norm EEG exp( corr )&#39;</span>},<span style="color:#e6db74">&#39;Location&#39;</span>,<span style="color:#e6db74">&#39;northwest&#39;</span>)
</code></pre></div><p><img src="../../images/eegmodelling/2.png" alt="hist features eeg correlations">
The z-score of the exponent of the EEG correlations (white bars) are now much closer to normally distributed. Since the task is binary classification, A probit model comes to mind.</p>
<h1 id="probit-regression">Probit Regression</h1>
<p>Since a probit model does an exponential transform on independent variables already, the raw correlation metrics will be used (blue bars).<br>
There are a large number of variables compared to observations (91 to 576), and no validation data exists as measurements are taken from one subjects EEG. So, even though the transformed data looks normally distributed, a pvalue of 0.01 will be used instead of 0.05 to be cautious of overfitting.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% Fit the correlation data to eye state with a binomial probability model</span>
mdl_probit = fitglm( x_train ,y_train,<span style="color:#e6db74">&#39;Distribution&#39;</span>,<span style="color:#e6db74">&#39;binomial&#39;</span>,<span style="color:#e6db74">&#39;link&#39;</span>,<span style="color:#e6db74">&#39;probit&#39;</span>);
<span style="color:#75715e">% remove variables sequentially starting with largest pvalue, untill all are under tolerance.</span>
mdl_probit = remlargePv3(mdl_probit,<span style="color:#e6db74">&#39;&#39;</span>,<span style="color:#ae81ff">0.01</span>);
yfit_Probit = predict(mdl_probit , x_train );
yfit_ProbitBinom = yfit_Probit<span style="color:#f92672">&gt;</span>=<span style="color:#ae81ff">0.5</span>;
[<span style="color:#f92672">~</span> ,<span style="color:#f92672">~</span>] = plotPrediction( yfit_ProbitBinom , yBinom_train , yfit_Probit , y_train , steplength_seconds );
</code></pre></div><p><img src="../../images/eegmodelling/3.png" alt="time series probit">
<img src="../../images/eegmodelling/4.png" alt="time series probit"></p>
<h2 id="model-evaluation">Model Evaluation</h2>
<p>At 97.7% accuracy, the performance looks really great - although this is a measure of in-sample performance. Because the dataset only contained one subjects' EEG readings, any generalisation performance metric reated using the original dataset would not at all reflect performance in the real-world business application.</p>
<p>Inpsecting the time series, errors are not bunched in particular timesteps, which is good for an autopilot system. Prediction probability scores are exactly 1 or zero, which hints at overfitting. The coefficient estimates statistics could reveal why;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% view the top 10 model parameters</span>
disp(mdl_probit.Coefficients(<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">10</span>,:))
</code></pre></div><pre><code>                    Estimate          SE           tStat       pValue
                   ___________    __________    ___________    ______
    (Intercept)    -1.6499e+15     6.366e+06    -2.5917e+08      0   
    x1              -6.289e+14    3.9605e+06    -1.5879e+08      0   
    x6             -1.1462e+15    5.4313e+06    -2.1104e+08      0   
    x7              1.1225e+15    6.8308e+06     1.6432e+08      0   
    x8              7.0188e+14    4.8371e+06      1.451e+08      0   
    x11            -9.9372e+14    9.6381e+06     -1.031e+08      0   
    x12            -1.3728e+15    5.1963e+06    -2.6418e+08      0   
    x15            -4.8003e+14    3.0494e+06    -1.5742e+08      0   
    x17             4.6081e+14    2.8604e+06      1.611e+08      0   
    x18            -5.7308e+14    3.3939e+06    -1.6885e+08      0   
</code></pre><p>These parameters are huge relative to the range of the predictor and response variables (-1 to 1), so this model is likely overfit and wouldn&rsquo;t perform well given new data. Very large coefficients make the model sensitive to variable changes, so could give a wildly different prediction if noise were in new data. For example, if some of the outliers removed at the start of the EDA were due to measurement device error, they could have dramatic effects in a real world application that used this model.</p>
<p>If large coefficients were a cause of poor generalisation performance, a Lasso regression could be used to incentivise smaller parameter magnitudes.</p>
<h1 id="lasso-probit-regression">Lasso Probit Regression</h1>
<p>Regression where the parameter search is incetivised for not only maximum likelihood but also small magnitude of parameters, is exactly a Lasso regression. Choosing how much importance to place on having small model parameters is done by creating a model for a range of importance factors - &ldquo;<em>Lambda</em>&quot;(λ), and inspecting performance of each model.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">%% Try a lasso binomial regresion to fit a &#34;probability of class&#34; </span>
kfolds=<span style="color:#ae81ff">7</span>;
[B,fitinfo]= lassoglm(x_train, y_train ,<span style="color:#e6db74">&#39;binomial&#39;</span>,<span style="color:#e6db74">&#39;CV&#39;</span>,kfolds,<span style="color:#e6db74">&#39;link&#39;</span>,<span style="color:#e6db74">&#39;probit&#39;</span>,<span style="color:#e6db74">&#39;NumLambda&#39;</span>,<span style="color:#ae81ff">20</span>);
<span style="color:#75715e">% plot cross validated performance scores for each lambda</span>
lassoPlot(B,fitinfo,<span style="color:#e6db74">&#39;plottype&#39;</span>,<span style="color:#e6db74">&#39;CV&#39;</span>);
set(gca,<span style="color:#e6db74">&#39;Yscale&#39;</span>,<span style="color:#e6db74">&#39;log&#39;</span>); ylabel([<span style="color:#e6db74">&#39;Log of &#39;</span>,get(get(gca,<span style="color:#e6db74">&#39;ylabel&#39;</span>),<span style="color:#e6db74">&#39;String&#39;</span>)]); grid on
legend(<span style="color:#e6db74">&#39;show&#39;</span>)
</code></pre></div><p><img src="../../images/eegmodelling/5.png" alt="time series probit"></p>
<h2 id="selecting-the-best">Selecting the best</h2>
<p>The cross validation process is in place to help select the right lambda (small parameter factor). Although just picking the best model of all lambda values' cross validated performance scores would be a biased process.</p>
<p>The reasoning is as follows. Varying lambda allows many models to be generated through shifting importance away from the sum of residuals, and to smaller parameters though lambda, which is not related to the dataset. If there are infinitely many lambda values, there would be infintely many objective functions for the parameters to be found. Statistically, a better model will be found than the regular least squares model just through this process of varying lambda. Just like a models parameters can be overfit to a dataset, here lambda allows overfitting of the modelling process.</p>
<p>To counter this selection bias, adhering to &ldquo;Occams Razor&rdquo; by favouring a smaller set of parameters - a model with stronger lambda value is selected, within 1 standard deviation of the &lsquo;best&rsquo; models performance;<br>
Cross validation of each lambda-model gives performance scores as a random variable (for the randomly k-folded data). The variance of these scores on the best model gives an upper bound on how far to move away from the optimal model, in terms of its lambda value. 1 standard deviation of best-lambda performance scores gives the lambda shown in the plot circled in blue. The green circle is the model with best cross validated performance on this dataset.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% Use the model with performance 1 SD below the best CV performance.</span>
idxLambdaMinDeviance = fitinfo.IndexMinDeviance;
B0 = fitinfo.Intercept(idxLambdaMinDeviance);
coefLASSO = [B0; B(:,idxLambdaMinDeviance)];
yfit_Lasso = glmval(coefLASSO, x_train ,<span style="color:#e6db74">&#39;probit&#39;</span>);
yfit_LassoBinom = (yfit_Lasso<span style="color:#f92672">&gt;</span>=<span style="color:#ae81ff">0.5</span>);
<span style="color:#75715e">% Plot prediction as time-series, and Confusion Matrix</span>
[<span style="color:#f92672">~</span>] = plotPrediction( yfit_LassoBinom , yBinom_train, yfit_Lasso , y_train , steplength_seconds ,<span style="color:#e6db74">&#39;confusion&#39;</span> );
</code></pre></div><p><img src="../../images/eegmodelling/6.png" alt="time series probit"></p>
<p>Another great model by using the correlations between EEG values, and an optimised lambda value.<br>
Because model selection is done through evaluating many models fit using a range of regulariser parameter weightings (λ), we are essentially &ldquo;seeing the output&rdquo; before selecting a model. This makes p-values of coefficients a compromised metric. In place of that, cross validation tests allowed selecting 1 standard deviation away from the best fit model, in favour of a simpler model.<br>
Again, we will look at the coefficients to speculate on generalisation performance, in the absence of validation data adequate for the business application.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% view magnitude of coefficients</span>
figure; bar( sort(abs(coefLASSO),<span style="color:#e6db74">&#39;descend&#39;</span>) )
title(<span style="color:#e6db74">&#39;Magnitude of coefficients for best Lasso probit model&#39;</span>)
</code></pre></div><p><img src="../../images/eegmodelling/7.png" alt="time series probit"><br>
Like the boxplot of correlation differences in the EDA showed, under half of the correlations have significant predictive power. Their is a lot of noise in most of the EEG correlation features. The model coefficients are now in the same order of magnitude as the model features themselves. This would likely have much better generalisation performance than the probit regression, which had extrememly large values in its parameters.</p>
<h1 id="partial-least-squares-regression">Partial Least Squares Regression</h1>
<p>Instead of assuming gaussian distribution of error terms like the probit model, the PLS algorithm minimises squared residuals after &lsquo;de-noising&rsquo; the input features to a lower dimensional &amp; orthogonal set. This is pertinent because a majority of the original EEG variables are correlated.</p>
<p>Now the normalised exponent of the correlation variables calculated earlier is used, as PLS only uses a squaring function to penalise residuals, which will be best utilised if the input variables are evenly &amp; symmetrically spread.</p>
<p>Considering there is such a large number of features for the number of samples, a modelling technique that utilises dimensionality reduction might lead in the right direction.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">[<span style="color:#f92672">~</span>,<span style="color:#f92672">~</span>,<span style="color:#f92672">~</span>,<span style="color:#f92672">~</span>,PctVar] = pca(xLogNorm_train);
<span style="color:#75715e">% first 95% of variance explained by k components</span>
ncomp = find( cumsum(<span style="color:#ae81ff">100</span><span style="color:#f92672">*</span>PctVar<span style="color:#f92672">./</span>(sum(PctVar))) <span style="color:#f92672">&gt;</span>=<span style="color:#ae81ff">95</span> , <span style="color:#ae81ff">1</span>);
figure;
plot(<span style="color:#ae81ff">1</span>:size(xLogNorm_train,<span style="color:#ae81ff">2</span>),cumsum(<span style="color:#ae81ff">100</span><span style="color:#f92672">*</span>PctVar<span style="color:#f92672">./</span>(sum(PctVar))),<span style="color:#e6db74">&#39;-b.&#39;</span>);
xlabel(<span style="color:#e6db74">&#39;Number of PCA components&#39;</span>);
ylabel(<span style="color:#e6db74">&#39;Percent Variance Explained in Data&#39;</span>);
hold on; plot([<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">100</span>], ones(<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">1</span>)<span style="color:#f92672">.*</span><span style="color:#ae81ff">95</span>,<span style="color:#e6db74">&#39;r-.&#39;</span>);
legend(<span style="color:#e6db74">&#39;cumulative variance in data explained by components&#39;</span>, [<span style="color:#e6db74">&#39;95% variance explained by &#39;</span>,num2str(ncomp),<span style="color:#e6db74">&#39; components&#39;</span>],<span style="color:#e6db74">&#39;location&#39;</span>,<span style="color:#e6db74">&#39;best&#39;</span>)
</code></pre></div><p><img src="../../images/eegmodelling/8.png" alt="time series probit"></p>
<p>This chart shows just how many of the EEG correlations were nearly meaningless in their predictive power.</p>
<h2 id="reducing-dimensionality-of-the-feature-set">Reducing dimensionality of the feature set.</h2>
<p>In the EDA when taking the perspective data was time-invariant, It wasn&rsquo;t obvious whether EEG values' were predictive of overall eye-state. (the transition &lsquo;spikes&rsquo; were time varying in their predictive power). Using correlations between EEGs showed predictive power, but meant making abstractions with the dataset, giving a larger number of new features (91 EEG correlations).</p>
<p>If the PLS algorithm projects the 91 correlations onto a new vector space of just 24 dimensions, its variation is explained 95% as well as using all 91 of the EEG correlations. By choosing a number of components from the Principal Component Analysis which doesn&rsquo;t include the output variable, the outcome variables are hidden from the parameter selection process - a hedge against overfitting.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% train a Partial least squares model using number of components that gives 95% variation in the PCA</span>
[xloads,yloads,xscores,yscores,betaPLS,<span style="color:#f92672">~</span>] = plsregress( xLogNorm_train , y_train ,ncomp);
yfitPLS = [ones(numel(windowstartId),<span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>betaPLS(<span style="color:#ae81ff">1</span>) <span style="color:#f92672">+</span> xLogNorm_train<span style="color:#f92672">*</span>betaPLS(<span style="color:#ae81ff">2</span>:<span style="color:#66d9ef">end</span>)];
<span style="color:#75715e">% Plot prediction as time-series, and Confusion Matrix</span>
[ <span style="color:#f92672">~</span> ] = plotPrediction( yfitPLS<span style="color:#f92672">&gt;</span>=<span style="color:#ae81ff">0.5</span> , yBinom_train, yfitPLS , y_train , steplength_seconds );
</code></pre></div><p><img src="../../images/eegmodelling/9.png" alt="time series probit"><br>
<img src="../../images/eegmodelling/10.png" alt="time series probit"></p>
<p>This model is good, doesn&rsquo;t require the assumption of normally distributed errors, and reduces the problems high dimensionality artificially created through the windowing method on EEG correlations. It&rsquo;s interesting to note the predictions are no longer considered probabilities in the range of 0 - 1, they are estimations of eye-state as decimals, and do not have the same meaning as predictions by the lasso or probit models.</p>
<h2 id="false-positives-vs-false-negatives-residual-skew">False positives vs. False Negatives <em>(residual skew)</em></h2>
<p>The 1&rsquo;s are classified wrong more than the 0&rsquo;s are. In the EDA, a boxplot of the EEGs showed longer tails on the right, meaning more weight in the lower values. If the Input variables to PLS model also has a skew, and it is heavier in observations of one eye-state vs another, it could cause the model to be asymmetric in the prediction of extreme errors, like those more wrong than the 0.5 probability cutoff for classification;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">fprintf(<span style="color:#e6db74">&#39;Median predictor skewness of all observations %.3g \nMedian predictor skewness in &#34;Open&#34; classes %.3g \nMedian predictor skewness in &#34;Closed&#34; classes %.3g&#39;</span> ,<span style="color:#75715e">...</span>
    median( moment( xLogNorm_train(:,:) , <span style="color:#ae81ff">3</span> ) ),<span style="color:#75715e">...</span>
    median( moment( xLogNorm_train(y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>,:) , <span style="color:#ae81ff">3</span>  ) ),<span style="color:#75715e">...</span>
    median( moment( xLogNorm_train(y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>,:) , <span style="color:#ae81ff">3</span>  ) ) )
</code></pre></div><pre><code>Median predictor skewness of all observations 0.494 
Median predictor skewness in &quot;Open&quot; classes 0.515 
Median predictor skewness in &quot;Closed&quot; classes 0.377
</code></pre><p>The parameter search process in PLS is via minimising a sum of squares (X^2), which does not consider the skewness (sum of X^3). The &ldquo;Closed&rdquo; class (0.36) has skewness with less extreme values than the &ldquo;Open&rdquo; class (0.54), so Closed classes may have a squared sum of residuals equal to that of Open classes, but in the Open class, there are more extreme outliers that contribute to the sum of squares, which results in more residuals crossing over the 0.5 probability threshold for classification betweeen 1 and 0.</p>
<p>The difference in skewness is not huge, but significant enough to imbalnce the confusion matrix: 15 false neegatives, vs 7 false positives.</p>
<h1 id="recurrent-neural-network---long-short-term-memory-lstm">Recurrent Neural Network - Long Short Term Memory (LSTM)</h1>
<p>A recurrent neural network (RNN) was selected for its ability to store memory of a particular pattern over many sequences. The &lsquo;transition spikes&rsquo; could be a good candidate for this, as they occur only a handful of times, and preceed long continuous sequences of one state or another.</p>
<p>An LSTM may be able to deal with the long input sequences required to detect these &lsquo;transition shapes&rsquo; which are 100-150 timesteps - about a second.</p>
<p>The EEG variables with pronounced transition spikes might be easier for the LSTM network to detect and remember. However, recalling from the EDA;</p>
<blockquote>
<p><strong>Insight #5</strong> <em>&ldquo;Similar patterns to transition-spikes occur at some non-transition timesteps in EEGs 1-4, 11-14, but EEGs 5 &amp; 8 have a uniquely pronounced signal at this time also&rdquo;</em></p>
</blockquote>
<p>This requires adding variables which do not have signals ahead of eye-state transitions. A &lsquo;false&rsquo; transition signal could be flagged with those EEGs which do not give transition signals normally, but still have the false transition pattern. EEGs 5 &amp; 8 flag the false pattern, EEGs 1, 2, 11 &amp; 13 consistently show transition signals ahead of state changes.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% downsample observations to the average of a 3 step window</span>
vars=[ [<span style="color:#ae81ff">5</span> , <span style="color:#ae81ff">8</span>] , [<span style="color:#ae81ff">1</span> <span style="color:#ae81ff">2</span> <span style="color:#ae81ff">11</span> <span style="color:#ae81ff">13</span>] ]; <span style="color:#75715e">% interesting Variables % [1 2 13 14];</span>
dsr = <span style="color:#ae81ff">3</span>; <span style="color:#75715e">% downsampling ratio</span>
dwn_TS = zeros( floor(N<span style="color:#f92672">/</span><span style="color:#ae81ff">3</span>)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span> , numel(vars)<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span> );
<span style="color:#66d9ef">for</span> sbp=vars
    dwn_TS(:,sbp) = arrayfun(@(ii) mean([TimeSeries_cln(ii<span style="color:#f92672">-</span>(dsr<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>):ii<span style="color:#f92672">+</span>(dsr<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>),sbp)]) , [dsr:dsr:numel(TimeSeries_cln(:,<span style="color:#ae81ff">1</span>))<span style="color:#f92672">-</span>(dsr<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)]<span style="color:#f92672">&#39;</span> );
<span style="color:#66d9ef">end</span>
dwn_TS(:,<span style="color:#ae81ff">15</span>) = arrayfun(@(ii) mean([idx_openclose(ii<span style="color:#f92672">-</span>(dsr<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>):ii<span style="color:#f92672">+</span>(dsr<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>), <span style="color:#ae81ff">1</span> )]) , [dsr:dsr:numel(TimeSeries_cln(:,<span style="color:#ae81ff">1</span>))<span style="color:#f92672">-</span>(dsr<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)]<span style="color:#f92672">&#39;</span> );
dwn_TS(:,<span style="color:#ae81ff">15</span>) = round(dwn_TS(:,<span style="color:#ae81ff">15</span>));
figure;
downsampleIndices = (dsr:dsr:numel(TimeSeries_cln(:,<span style="color:#ae81ff">1</span>))<span style="color:#f92672">-</span>(dsr<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))<span style="color:#f92672">&#39;</span>;
plot( TimeSeries_cln(:,<span style="color:#ae81ff">1</span>) ); hold on; plot(downsampleIndices,dwn_TS(:,<span style="color:#ae81ff">1</span>),<span style="color:#e6db74">&#39;r*-&#39;</span>); grid minor; 
xlim([<span style="color:#ae81ff">6570</span> <span style="color:#ae81ff">6620</span>]); legend(<span style="color:#e6db74">&#39;Raw EEG#1&#39;</span>,<span style="color:#e6db74">&#39;Downsampled EEG#1&#39;</span>);
ylabel(<span style="color:#e6db74">&#39;EEG value&#39;</span>); xlabel(<span style="color:#e6db74">&#39;timestep&#39;</span>);
title(<span style="color:#e6db74">&#39;Original EEG signal with it&#39;&#39;s downsampled approximation&#39;</span>)
</code></pre></div><p><img src="../../images/eegmodelling/11.png" alt="time series probit"><br>
The red line is the average of original sequence across a 5-step window, which shifts forward by 3 steps each time. New downsampled data becomes 1/3 the length allowing for faster training, and a less noisy input signal.</p>
<p>From the EDA;</p>
<blockquote>
<p><strong>Insight #4:</strong> <em>&ldquo;Shape' of Lead signal is independent of starting magnitude.&quot;</em></p>
</blockquote>
<p>This means the network will have more meaningful variation in the input data if we remove trend from the EEGs, and use the difference between points.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% reshape the downsampled EEGs: [timesteps, (none) , variable]</span>
Ts_X = permute( dwn_TS( : , vars) , [<span style="color:#ae81ff">1</span> <span style="color:#ae81ff">3</span> <span style="color:#ae81ff">2</span>] );
<span style="color:#75715e">% for each variable, calculate the moving sum of differences, then normalize into the range [-1 , 1]</span>
<span style="color:#66d9ef">for</span> ii=<span style="color:#ae81ff">1</span>:size(Ts_X,<span style="color:#ae81ff">3</span>) 
    Xdiff = [<span style="color:#ae81ff">0</span>; diff(Ts_X(:,:,ii)) ];
    Ts_X(:,:,ii) = movsum( [ Xdiff ],[<span style="color:#ae81ff">3</span> <span style="color:#ae81ff">0</span>]);
    Ts_X(:,:,ii) = normalize( Ts_X(:,:,ii), <span style="color:#e6db74">&#39;range&#39;</span>,[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">1</span>]);
<span style="color:#66d9ef">end</span>
Ts_Y = permute( dwn_TS( : , <span style="color:#66d9ef">end</span> ) , [<span style="color:#ae81ff">1</span> <span style="color:#ae81ff">3</span> <span style="color:#ae81ff">2</span>]);
Ts_Y = permute(dummyvar(categorical(Ts_Y)) , [<span style="color:#ae81ff">1</span> <span style="color:#ae81ff">3</span> <span style="color:#ae81ff">2</span>]);
<span style="color:#75715e">% plot differneced normalised variable with/without moving sum applied.</span>
figure;
plot([Ts_X(:,<span style="color:#ae81ff">1</span>,ii), normalize(Xdiff,<span style="color:#ae81ff">1</span>,<span style="color:#e6db74">&#39;range&#39;</span>,[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">1</span>]) ])
xlim([<span style="color:#ae81ff">420</span> <span style="color:#ae81ff">500</span>])
legend(<span style="color:#e6db74">&#39;Normalised moving sum of differenced #EEG 2&#39;</span>,<span style="color:#e6db74">&#39;Normalised differenced #EEG 2&#39;</span>); xlabel(<span style="color:#e6db74">&#39;timestep&#39;</span>);
title(<span style="color:#e6db74">&#39;3-step Moving sums effect on EEG&#39;</span>); ylabel(<span style="color:#e6db74">&#39;EEG feature value&#39;</span>); grid minor
</code></pre></div><p><img src="../../images/eegmodelling/12.png" alt="time series probit"><br>
Now the transition lead signals values are beggining from the same base. These &lsquo;transition spikes&rsquo; happen over 100-150 timesteps, so a moving sum of the differenced EEG will help remove some noise from the signal.</p>
<h1 id="lstm-shaping-training-samples">LSTM: Shaping training samples</h1>
<p>Each input-output pair of a sample learnt by the RNN is a sequence of feature vectors, predicting another sequence of eye-states (2-classes). The downsampled EEG features are reshaped, and grouped into batches for mini-batch training.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% create minibatches of the sequences of variables.</span>
seqlen_in = <span style="color:#ae81ff">40</span>; <span style="color:#75715e">% input sequence length</span>
seqlen_out=<span style="color:#ae81ff">5</span>; <span style="color:#75715e">% target sequence length</span>
Nbatches = <span style="color:#ae81ff">12</span>; <span style="color:#75715e">% number of batches in each training epoch</span>
[DataX_batched, DataY_batched, Xind_c, Yind_c, singleseqlen] = batchdatasets( Nbatches, Ts_X , Ts_Y , <span style="color:#e6db74">&#39;seq2batch&#39;</span> ,seqlen_in, seqlen_out);
<span style="color:#75715e">% size of each minibatch input and output</span>
InputDataSize = size(DataX_batched{<span style="color:#ae81ff">1</span>});
OutputDataSize = size(DataY_batched{<span style="color:#ae81ff">1</span>});
batchsize = size(DataX_batched{<span style="color:#ae81ff">1</span>},<span style="color:#ae81ff">1</span>);
disp([<span style="color:#e6db74">&#39;Input sequences&#39;</span>; DataX_batched ])
</code></pre></div><pre><code>    'Input sequences'
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
    [400×40×6 double]
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">disp([<span style="color:#e6db74">&#39;1st batch of Target sequences&#39;</span>; DataY_batched(<span style="color:#ae81ff">1</span>) ])
</code></pre></div><pre><code>    '1st batch of Target sequences'
    [400×5×2 double               ]
</code></pre><p>Each input sample the network ingests is a 40-step sequence of 6 features which begins after the last step of the prior batch. The output sample is a 5-step sequence of 2 dimesnsions, one for each possible class the eye-state can take.</p>
<p>The entire 117 seconds sequence is now in 4992 steps, so dividing it into 12 batches of 400 input-output pairs. The remaining 192 samples will be omitted so the the network training algorithm can use even batch sizes, and train faster.</p>
<p>The indices of each sample help to show how input&rsquo;s are presented to the network;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">disp(<span style="color:#e6db74">&#39;First 10 steps of input sequence for samples 1-3 in mini-batch #1&#39;</span>), disp( Xind_c(<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">10</span>) )
</code></pre></div><pre><code>First 10 steps of input sequence for samples 1-3 in mini-batch #1
     1     2     3     4     5     6     7     8     9    10
     2     3     4     5     6     7     8     9    10    11
     3     4     5     6     7     8     9    10    11    12
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">disp(<span style="color:#e6db74">&#39;Last 10 steps of samples 1-3&#39;</span>), disp( Xind_c(<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">3</span>,<span style="color:#66d9ef">end</span><span style="color:#f92672">-</span><span style="color:#ae81ff">9</span>:<span style="color:#66d9ef">end</span>) )
</code></pre></div><pre><code>Last 10 steps of samples 1-3
    31    32    33    34    35    36    37    38    39    40
    32    33    34    35    36    37    38    39    40    41
    33    34    35    36    37    38    39    40    41    42
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">disp(<span style="color:#e6db74">&#39;Samples 1-3 are timesteps continuing from input sequence&#39;</span>) , disp( Yind_c(<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">3</span>, : ) )
</code></pre></div><pre><code>Samples 1-3 are timesteps continuing from input sequence
    41    42    43    44    45
    42    43    44    45    46
    43    44    45    46    47
</code></pre><p>The first sample in mini-batch #1 ends at t=40, and this cell state is passed to the first sample in mini-batch #2 whose values are from t=41 to t=80. This way, the LSTM can retain &lsquo;context information for much longer than 40 timesteps. Only mini-batch #1 will have no cell state passed to it, so relies on only the first 40 input steps to make it&rsquo;s predictions.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">disp(<span style="color:#e6db74">&#39;Input sequences are continued in the following minibatch&#39;</span>), disp( Xind_c(<span style="color:#ae81ff">400</span> <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">3</span>),<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">10</span>) )
</code></pre></div><pre><code>Input sequences are continued in the following minibatch
    41    42    43    44    45    46    47    48    49    50
    42    43    44    45    46    47    48    49    50    51
    43    44    45    46    47    48    49    50    51    52
</code></pre><p>Visualising the sequences for all 6 selected EEG variables, at sample numbers 1 &amp; 21 shows how within a batch, network is exposed to overlapping sequences;</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">% Plot input-output pairs from the batched data</span>
<span style="color:#75715e">% Find eye-state transition timesteps</span>
eyeOid = find([ <span style="color:#ae81ff">0</span> ;diff( Ts_Y(:,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>),<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>)]<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>);
eyeCid = find([ <span style="color:#ae81ff">0</span> ;diff( Ts_Y(:,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>),<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>)]<span style="color:#f92672">==-</span><span style="color:#ae81ff">1</span>);
<span style="color:#75715e">% timestep of first Closed to Open transition</span>
smplB = find(Yind_c(:,<span style="color:#ae81ff">1</span>)<span style="color:#f92672">==</span>eyeOid(<span style="color:#ae81ff">1</span>),<span style="color:#ae81ff">1</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">2</span>;
<span style="color:#75715e">% sample 20 steps prior</span>
smplA = smplB<span style="color:#f92672">-</span><span style="color:#ae81ff">20</span>;
<span style="color:#75715e">% plot EEGs at sample A &amp; B</span>
figure;
pEA = plot( Xind_c( smplA ,: ) , squeeze(DataX_batched{<span style="color:#ae81ff">1</span>}( smplA ,:,:)),<span style="color:#e6db74">&#39;b&#39;</span>,<span style="color:#e6db74">&#39;LineWidth&#39;</span>,<span style="color:#ae81ff">1.5</span>); hold on;
pEB = plot( Xind_c( smplB ,: ) , squeeze(DataX_batched{<span style="color:#ae81ff">1</span>}(smplB,:,:)),<span style="color:#e6db74">&#39;r.-&#39;</span>);
ylabel(<span style="color:#e6db74">&#39;Input feature value&#39;</span>);
<span style="color:#75715e">% Plot target sequence following input samples.</span>
yyaxis right; yticks([<span style="color:#ae81ff">0</span> <span style="color:#ae81ff">1</span>]); yticklabels(gca,{<span style="color:#e6db74">&#39;Open&#39;</span>,<span style="color:#e6db74">&#39;Closed&#39;</span>})
pSA = plot(Yind_c( smplA ,:), squeeze(DataY_batched{<span style="color:#ae81ff">1</span>}(smplA,:,<span style="color:#ae81ff">2</span>)),<span style="color:#e6db74">&#39;b-d&#39;</span>,<span style="color:#e6db74">&#39;MarkerFaceColor&#39;</span>,<span style="color:#e6db74">&#39;b&#39;</span>);
title(<span style="color:#e6db74">&#39;Input-Output pairs from training minibatch #1&#39;</span>)
pSB = plot(Yind_c( smplB ,:), squeeze(DataY_batched{<span style="color:#ae81ff">1</span>}(smplB,:,<span style="color:#ae81ff">2</span>)),<span style="color:#e6db74">&#39;r-d&#39;</span>,<span style="color:#e6db74">&#39;MarkerFaceColor&#39;</span>,<span style="color:#e6db74">&#39;r&#39;</span>);
xlabel(<span style="color:#e6db74">&#39;timestep&#39;</span>); ylabel(<span style="color:#e6db74">&#39;Eye-state&#39;</span>)
legend([pEA(<span style="color:#ae81ff">1</span>),pEB(<span style="color:#ae81ff">1</span>),pSA(<span style="color:#ae81ff">1</span>),pSB(<span style="color:#ae81ff">1</span>)],<span style="color:#e6db74">&#39;EEGs @ sample sequence A&#39;</span>,<span style="color:#e6db74">&#39;EEGs @ sample sequence B&#39;</span>,<span style="color:#e6db74">&#39;Eye state @ end of seq A&#39;</span>,<span style="color:#e6db74">&#39;Eye state @ end of seq B&#39;</span>,<span style="color:#e6db74">&#39;location&#39;</span>,<span style="color:#e6db74">&#39;north&#39;</span>)
</code></pre></div><p><img src="../../images/eegmodelling/13.png" alt="input-output pairs from minibatch">
Here the network will have to learn that the &lsquo;red&rsquo; sequences indicate a transition from open to close, using only the 40-step sequence as context. The samples that follow in mini-batch #2 will have this context passed to them (they will start at t=61).</p>
<h2 id="maintaining-cell-memory-across-mini-batches">Maintaining cell-memory across mini-batches</h2>
<p>Each mini-batch contains 400 samples of sequences 40 timesteps long. Visualising the mini-batches shows that each is exposed to a maximum of 2 trainsition spikes. This could be a problem for training, and put limitations on how the model is used for prediction.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">figure(<span style="color:#e6db74">&#39;Position&#39;</span>,[<span style="color:#ae81ff">147</span> <span style="color:#ae81ff">549</span> <span style="color:#ae81ff">1182</span> <span style="color:#ae81ff">363</span>]);
Cmap = colormap;    hold on;
<span style="color:#66d9ef">for</span> bi = <span style="color:#ae81ff">1</span>:Nbatches
    bInd = (<span style="color:#ae81ff">1</span>:<span style="color:#ae81ff">440</span>)<span style="color:#f92672">+</span> <span style="color:#ae81ff">400</span><span style="color:#f92672">*</span>(bi<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>);
    plot(bInd, squeeze(Ts_X(bInd,<span style="color:#ae81ff">1</span>,:))<span style="color:#f92672">&#39;+</span>[<span style="color:#ae81ff">1</span>:size(Ts_X,<span style="color:#ae81ff">3</span>)]<span style="color:#f92672">&#39;</span> ,<span style="color:#e6db74">&#39;Color&#39;</span>,Cmap( floor(<span style="color:#ae81ff">1</span><span style="color:#f92672">+</span>rem(bi,<span style="color:#ae81ff">3</span>)<span style="color:#f92672">*</span>(<span style="color:#ae81ff">64</span><span style="color:#f92672">/</span><span style="color:#ae81ff">3</span>)) ,:) ,<span style="color:#e6db74">&#39;HandleVisibility&#39;</span>,<span style="color:#e6db74">&#39;off&#39;</span>);
<span style="color:#66d9ef">end</span>
yticklabels <span style="color:#e6db74">&#39;&#39;</span>;
yyaxis right; bar( dwn_TS( : , <span style="color:#66d9ef">end</span> ) ,<span style="color:#e6db74">&#39;LineStyle&#39;</span>,<span style="color:#e6db74">&#39;none&#39;</span>,<span style="color:#e6db74">&#39;FaceAlpha&#39;</span>,<span style="color:#ae81ff">0.1</span> ,<span style="color:#e6db74">&#39;FaceColor&#39;</span>,<span style="color:#e6db74">&#39;r&#39;</span>); yticklabels <span style="color:#e6db74">&#39;&#39;</span>;
title(<span style="color:#e6db74">&#39;EEG features color coded by training mini-batch&#39;</span>); legend(<span style="color:#e6db74">&#39;Eye state closed&#39;</span>)
</code></pre></div><p><img src="../../images/eegmodelling/14.png" alt="features across mini-batches">
The first mini-batch propogated through time by the network (blue) passes it&rsquo;s memory state/context to the next batch of 440 steps (green), which then passes to the next 440 steps (purple), and so on.</p>
<h2 id="convergence-of-lstm-with-memory-passed-through-mini-batches">Convergence of LSTM with memory passed through mini-batches;</h2>
<p>Parameters determine cell state, used to predict and update parameters based on that error: $$ \theta_b^i =g\left(C_{\mathit{\mathbf{b}}}^{\mathit{\mathbf{i}}} ;,X_b ;,Y_{b;} \right)+\theta_{b-1}^i $$</p>
<p>The cell state <em>prior</em> to a parameter 
update is used to calculate cell in the next batch: 
$$ C_b =\mathit{\mathbf{F}}\left(C_{\mathit{\mathbf{b}}-1}^{\mathit{\mathbf{i}}-1} 
;,\theta_{\mathit{\mathbf{b}}-1}^{\mathit{\mathbf{i}}} ;,{\mathit{\mathbf{X}}}_{\mathit{\mathbf{b}}} 
\right) $$
So, the cell state passed forward as &lsquo;context&rsquo; now takes on a different 
meaning because the parameters aren&rsquo;t the same as the ones that created the 
&lsquo;context&rsquo; / cell state. This implies a leak in information through training 
epochs. i.e.
$$C_{\mathit{\mathbf{b}}}^{\mathit{\mathbf{i}}} \not= C_{\mathit{\mathbf{b}}}^{\mathit{\mathbf{i}}-1}$$</p>
<p>$$\theta: network\ parameter\ setting,\ C: memory\ cell\ state,\ g\left(·\right): parameter\ update\ rule,\ \mathit{\mathbf{F}}\left(·\right): memory\ calculation\ b,i:\ batch\ and\ epoch.$$</p>
<p>Without passing memory through mini-batches, the parameter update will 
optimise the network for only the inputs of that one mini-batch, which isn&rsquo;t 
a problem, because over 100&rsquo;s of epochs all batches are seen, and they remain 
the same through the epochs. But a memory cell is putting a different &lsquo;lens&rsquo; 
on those same inputs that are repeated over 100s of epochs, therefore all parameter 
updates are based off different inputs. There is less consistency for the network 
to learn.</p>
<p>Because only 1-2 of the transition-patterns the network is trying to learn 
occur per batch, if two adjacent patterns are very different, the leak in memory 
&lsquo;meaning&rsquo; could be exacerbated by the time training of that same batch happens 
again. Careful selection of training hyperparmeters is needed to optimise convergence.</p>
<p><em>Cell state is a function of a lagged parameter setting and lagged cell 
state, across all batches and iterations;</em></p>
<p>$$ \begin{array}{l}C_b =\mathit{\mathbf{F}}\left({\mathit{\mathbf{C}}} {\mathit{\mathbf{b}}-1} 
;,\theta_{\mathit{\mathbf{b}}-1}^{\mathit{\mathbf{i}}} ;,{\mathit{\mathbf{X}}} {\mathit{\mathbf{b}}} 
\right) \\ C_0 =\mathit{\mathbf{F}}\left(\left\lbrack 0\right\rbrack ;,\theta_{\mathit{\mathbf{b}}}^{\mathit{\mathbf{i}}-1} 
;,{\mathit{\mathbf{X}}}_{\mathit{\mathbf{b}}} \right)\end{array} $$</p>
<h2 id="real-world-implementation-of-a-memory-preserving-lstm">Real-world implementation of a memory preserving LSTM</h2>
<p>Passing cell state through sequences has an impact on the real-world application of this model once trained. Each sample&rsquo;s prediction in the sequence is dependent on all the samples leading up to it. So, without pre-computing all those prior samples the device using this model would be completely useless. The user would have to replicate the first 440 samples the LSTM was fed by opening then shutting eyes for about 1.5 seconds, just like in the dataset. Then, the network would create the cell state in the same way it does during training.</p>
<h2 id="defining-the-network-topology">Defining the network topology</h2>
<p>The output sequence length requires a 5-timestep length, but the transition patterns in the EEGs occur over a much longer period. An encoder-decoder model permits different length sequences of input &amp; output, so that will be used with a regular feed forward layer at the end of each decoder step to convert the values into the range 0 - 1, and do the classification using softmax activation.</p>
<p>Probit, Lasso &amp; PLS models used 91 correlation features, though only 20 or so contained the large majority of the explanatory power. RNN training takes a long time because each step needs to be calculated in series, not paralellel - so the network will be created with 45 hidden units in both the encoder and decoder.</p>
<p>The function <strong>GenerateNNetLayer.m</strong> takes batch size, number of units &amp; other parameters to define a layer in the network, with weights pre-initialised.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">%% Topology</span>
    epochs = <span style="color:#ae81ff">800</span>;
    trainingSettings.GDOptimizer = <span style="color:#e6db74">&#39;Adam&#39;</span>;
    trainingSettings.learnrate = <span style="color:#ae81ff">0.001</span>;
    trainingSettings.LossType = &#34;MultiClassCrossEntropy&#34;;
    
    <span style="color:#75715e">% input embedding</span>
    encoderHUs = <span style="color:#ae81ff">45</span>;
    decoderHUs = <span style="color:#ae81ff">45</span>;
    classifierHUs = OutputDataSize(<span style="color:#ae81ff">3</span>);
    
    <span style="color:#75715e">% create Encoder</span>
    [NNLayerEnc] = GenerateNNetLayer( encoderHUs , InputDataSize(<span style="color:#ae81ff">1</span>) , InputDataSize(<span style="color:#ae81ff">3</span>) , &#34;LSTM&#34; , &#34;tanh&#34; <span style="color:#75715e">...</span>
        , InputDataSize(<span style="color:#ae81ff">2</span>) , struct(<span style="color:#e6db74">&#39;resetstate&#39;</span>,false,<span style="color:#e6db74">&#39;predictsequence&#39;</span>,false ) );
    <span style="color:#75715e">% create Decoder</span>
    [NNLayerDec] = GenerateNNetLayer( decoderHUs , InputDataSize(<span style="color:#ae81ff">1</span>) , NNLayerEnc.Nunits , &#34;LSTM&#34; , &#34;tanh&#34; <span style="color:#75715e">...</span>
        , OutputDataSize(<span style="color:#ae81ff">2</span>) , struct(<span style="color:#e6db74">&#39;resetstate&#39;</span>,false,<span style="color:#e6db74">&#39;predictsequence&#39;</span>,true ) );
    
    <span style="color:#75715e">% Projection Layer to Output tokens</span>
    [NNLayerFinal] = GenerateNNetLayer( classifierHUs , OutputDataSize(<span style="color:#ae81ff">1</span>) , NNLayerDec.Nunits , &#34;dense&#34; , &#34;softmax&#34; );
    
    NNModels = [{NNLayerEnc},{NNLayerDec},{NNLayerFinal}];
    
    
disp([newline ,<span style="color:#e6db74">&#39;Input Layer (Encoder); &#39;</span>]) , disp( NNModels{<span style="color:#ae81ff">1</span>} )
</code></pre></div><pre><code>Input Layer (Encoder); 
                   Type: &quot;LSTM&quot;
                 ActFcn: &quot;tanh&quot;
                 Nunits: 45
                 XInput: [400×40×6 double]
            Activations: [1×1 struct]
                Weights: [1×1 struct]
                BP_pOut: [1×1 struct]
                   dEdW: [1×1 struct]
           Connectivity: [6×45 double]
        predictsequence: 0
    PropBatchinSequence: 0
             resetstate: 0
        SelfReferencing: 0
         TeacherForcing: 0
               Peephole: 0
              Attention: 0
                 BiLSTM: 0
              InputMask: [1×1 struct]
                curStep: 1
                Nstates: 40
              Inistates: [1×1 struct]
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">disp([newline ,<span style="color:#e6db74">&#39;Prediction Layer (Decoder); &#39;</span>]) , disp( NNModels{<span style="color:#ae81ff">2</span>} )
</code></pre></div><pre><code>Prediction Layer (Decoder); 
                   Type: &quot;LSTM&quot;
                 ActFcn: &quot;tanh&quot;
                 Nunits: 45
                 XInput: [400×5×45 double]
            Activations: [1×1 struct]
                Weights: [1×1 struct]
                BP_pOut: [1×1 struct]
                   dEdW: [1×1 struct]
           Connectivity: [45×45 double]
        predictsequence: 1
    PropBatchinSequence: 0
             resetstate: 0
        SelfReferencing: 0
         TeacherForcing: 0
               Peephole: 0
              Attention: 0
                 BiLSTM: 0
              InputMask: [1×1 struct]
                curStep: 1
                Nstates: 5
              Inistates: [1×1 struct]
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">disp([newline ,<span style="color:#e6db74">&#39;Final classification Layer; &#39;</span>]) , disp( NNModels{<span style="color:#ae81ff">3</span>} )
</code></pre></div><pre><code>Final classification Layer; 
            Type: &quot;dense&quot;
          ActFcn: &quot;softmax&quot;
          Nunits: 2
          XInput: [400×45 double]
     Activations: [1×1 struct]
         Weights: [1×1 struct]
         BP_pOut: [1×1 struct]
            dEdW: [1×1 struct]
    Connectivity: [45×2 double]
</code></pre><p>The encoder &amp; decoder are single direction LSTMs. The decoder doesn&rsquo;t take the output of it&rsquo;s recurrent activations as input to the next step, only the encoders last activation and cell state is used as context. The internal memory cell state, once initialised with the encoder output, holds all information needed to correctly predict 5 sequential classes.</p>
<h1 id="lstm-model-training--prediction">LSTM Model Training &amp; Prediction</h1>
<p>Now the network hyperparameters &amp; topology have been set, the training algorithm can search for the best parameter settings for the objective</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab"><span style="color:#75715e">%% call training algorithm to learn the EEG dependencies</span>
<span style="color:#66d9ef">try</span>
    load(<span style="color:#e6db74">&#39;EEGworkspace_45Hus3downsampleV_13_8_11_1_2_seqIn40seqOut5_gradclip_minus1to1_B.mat&#39;</span>)
<span style="color:#66d9ef">catch</span> ME
    [NNModels, <span style="color:#f92672">~</span>, <span style="color:#f92672">~</span> , <span style="color:#f92672">~</span> ] = <span style="color:#75715e">...</span>
        TrainSequnceNNetV3(NNModels, epochs, trainingSettings , DataX_batched, DataY_batched, [], []);
<span style="color:#66d9ef">end</span>
printNNetsettings(NNModels{<span style="color:#66d9ef">end</span>}.trainingInformation)
</code></pre></div><pre><code>    Network Settings:
               gradclip :  : True 
                LossFcn :  : @(Pred,Real)-sum(Real.*log(Pred),3) 
             Loss_delta :  : @(Pred,Real)CrossEntropyDeriv_ifisnan(Real,Pred) 
seedStateFromPriorLayer :  : False 
         LayerOperation : 
    &quot;regular&quot;    &quot;RepeatVector&quot;    &quot;TimeDistributed&quot;
    &quot;LSTM&quot;       &quot;LSTM&quot;            &quot;dense&quot;          
        NewDataperEpoch :  : False 
</code></pre><p>First layer, the encoder, is a 40-step LSTM ingesting the EEG sequences. 2nd Layer is a 5-step LSTM which takes last output of encoder, uses it as input for all 5 of the decoders&rsquo; timesteps. Memory state in the 2nd layer (decoder) is initialised with the last memory state of the 1st layer (encoder). Final 3rd layer is a regular fully connected softmax layer which makes 5 classifications of open or cloed eyes, with each of the 5 recurrent outputs from the 2nd layer (decoder).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">figure;
plot(NNModels{<span style="color:#66d9ef">end</span>}.LossHistory); xlabel(<span style="color:#e6db74">&#39;epoch&#39;</span>); ylabel(<span style="color:#e6db74">&#39;Cross-entropy loss&#39;</span>); title(<span style="color:#e6db74">&#39;Training loss&#39;</span>)
</code></pre></div><p><img src="../../images/eegmodelling/15.png" alt="LSTM training loss"><br>
Training loss looks very volatile, proably due to the long sequences it&rsquo;s learning. Other reasons could be;</p>
<ol>
<li><strong>Dataset</strong> isn&rsquo;t varied / large enough. The model has learnt the data (overfit).</li>
<li><strong>Learning rate</strong> - too high. When network approaches a minima in the solution space, it could overshoot as it heads toward an optimal set of parameters.</li>
<li><strong>Optimiser</strong> - Adadelta could work, and would make learning rate selection obsolete.</li>
<li><strong>Hidden units</strong> - too many. 30HUs gives over 10,000 parameters, for just 4000 observations. Lasso model, while not a neural network models had just 20-30 relevant parameters.</li>
<li><strong>Hidden units</strong> - too few for sequence length of 40. Since memory state is passed batch to batch, perhaps sequence length of 40 isn&rsquo;t necessary to build up a context for the decoder to predict class.</li>
<li><strong>Initialisation of memory state</strong> - passing state from mini-batch to mini-batch meant network learns each batch from a moving foundation. Memory state passed from mini-batch is done before the weight update step, meaning the new batch is learning from a starting state that will not be repeated in the next epoch. A longer input sequence with no memory passing could be an alternative to learning the transition patterns.
(<em>A few more hyperparmeters were tested, and shown in the summary.</em>)</li>
</ol>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">Re<span style="color:#f92672">-</span>running the algorithm in inference mode;
    <span style="color:#75715e">% Run an inference only loop over the dataset with the trained model</span>
    [NNModels, Predictions, ErrorMetric1, ErrorMetric2] = <span style="color:#75715e">...</span>
        TrainSequnceNNetV3(NNModels, epochs, trainingSettings , DataX_batched, DataY_batched, [], [],true,false);
    ABSE_seqOut = <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> mean(round(Predictions(:,:,<span style="color:#ae81ff">1</span>))<span style="color:#f92672">==</span>DataY_unbatched(:,:,<span style="color:#ae81ff">1</span>));
    disp([[<span style="color:#e6db74">&#39;Accuracy across output steps t1 - t5:&#39;</span>,], sprintf(<span style="color:#e6db74">&#39; %0.2f%%  &#39;</span>, (<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>ABSE_seqOut)<span style="color:#f92672">*</span><span style="color:#ae81ff">100</span> )])
</code></pre></div><pre><code>Accuracy across output steps t1 - t5: 93.85%   95.17%   95.27%   95.38%   95.42%  
</code></pre><p>Model accuracy was competitive with the Lasso, Probit and Partial least squares models.</p>
<p>The neural network used training target sequences of 0.11 seconds, correlation data windows were 0.21 seconds. A like-for-like comparison would need to match the length of prediction windows between the two models.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">Unpacking the prediction data and visualising;
    <span style="color:#75715e">% unroll prediction, take the average of each sequence from consecutive</span>
    <span style="color:#75715e">% starting points</span>
    [Xunbatch, Yunbatch ] = batchdatasets( [] , DataX_batched, DataY_batched, <span style="color:#e6db74">&#39;unbatch_seq2batch&#39;</span>, Xind_c , Yind_c  );
    
    <span style="color:#75715e">% vector containing average of all 5-step predictions &amp; errors (5 steps * 4800 samples = 24000 predictions)</span>
    VectorisedPrediction = reshape(Predictions(:,:,<span style="color:#ae81ff">2</span>), [numel(Predictions(:,:,<span style="color:#ae81ff">2</span>)) , <span style="color:#ae81ff">1</span>] );
    yfitRNNLSTM = accumarray( Yind_c(:) , VectorisedPrediction ,[],@mean , NaN);
    
    <span style="color:#75715e">% average of all predictions</span>
    
    AbsErr = (abs( yfitRNNLSTM <span style="color:#f92672">-</span> Yunbatch(:,<span style="color:#ae81ff">2</span>) ));
    <span style="color:#75715e">% entire sequence, positive is eyes closed.</span>
    TargetSeq = Yunbatch(:,<span style="color:#ae81ff">2</span>);<span style="color:#75715e">%accumarray( Yind_c(:) , TrgVect ,[],@mean , NaN);</span>
    
    <span style="color:#75715e">% plot prediction error, and key EEG values across the sequnce</span>
        figure(<span style="color:#e6db74">&#39;Position&#39;</span>,[<span style="color:#ae81ff">141</span> <span style="color:#ae81ff">471</span> <span style="color:#ae81ff">1471</span> <span style="color:#ae81ff">470</span>]);
    subplot(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>); title(<span style="color:#e6db74">&#39;Prediction Error&#39;</span>)
    bh = bar(<span style="color:#ae81ff">1</span>:numel(AbsErr),round(yfitRNNLSTM),<span style="color:#e6db74">&#39;LineStyle&#39;</span>,<span style="color:#e6db74">&#39;none&#39;</span>,<span style="color:#e6db74">&#39;FaceAlpha&#39;</span>,<span style="color:#ae81ff">0.2</span>); 
    xlim([<span style="color:#ae81ff">0</span> max(Yind_c(:))])
    yyaxis right; 
    bar(<span style="color:#ae81ff">1</span>:numel(AbsErr), AbsErr ); 
    ylim([<span style="color:#ae81ff">0</span> <span style="color:#ae81ff">1</span>]); set(gca,<span style="color:#e6db74">&#39;Ytick&#39;</span>,[<span style="color:#ae81ff">0</span> <span style="color:#ae81ff">1</span>]); 
    legend(<span style="color:#e6db74">&#39;Eye state prediction (1=Closed)&#39;</span>,<span style="color:#e6db74">&#39;Prediction error&#39;</span>,<span style="color:#e6db74">&#39;location&#39;</span>,<span style="color:#e6db74">&#39;north&#39;</span>); 
    title(<span style="color:#e6db74">&#39;Prediction vs True class&#39;</span>)
    
    subplot(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>); title(<span style="color:#e6db74">&#39;EEGs (normalised, downsampled 3:1)&#39;</span>)
    plot(<span style="color:#ae81ff">1</span>:numel(AbsErr), normalize( movmean( dwn_TS( <span style="color:#ae81ff">1</span>:numel(AbsErr) ,vars([<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">5</span>,<span style="color:#ae81ff">1</span>]) ),<span style="color:#ae81ff">20</span> , <span style="color:#ae81ff">1</span>), <span style="color:#ae81ff">1</span> ,<span style="color:#e6db74">&#39;range&#39;</span>)<span style="color:#f92672">-</span><span style="color:#ae81ff">0.5</span> );
    yyaxis right; 
    bar( <span style="color:#ae81ff">1</span>:numel(AbsErr),TargetSeq ,<span style="color:#e6db74">&#39;LineStyle&#39;</span>,<span style="color:#e6db74">&#39;none&#39;</span>,<span style="color:#e6db74">&#39;FaceAlpha&#39;</span>,<span style="color:#ae81ff">0.2</span> ,<span style="color:#e6db74">&#39;FaceColor&#39;</span>,bh.FaceColor); 
    set(gca,<span style="color:#e6db74">&#39;Ytick&#39;</span>,[<span style="color:#ae81ff">0</span> <span style="color:#ae81ff">1</span>])
    xlim([<span style="color:#ae81ff">0</span> max(Yind_c(:))])
    legend(<span style="color:#e6db74">&#39;EEG 1&#39;</span>,<span style="color:#e6db74">&#39;EEG 2&#39;</span>,<span style="color:#e6db74">&#39;EEG 13&#39;</span>,<span style="color:#e6db74">&#39;Target eye state (1=Closed)&#39;</span>,<span style="color:#e6db74">&#39;location&#39;</span>,<span style="color:#e6db74">&#39;north&#39;</span>)    
    title(<span style="color:#e6db74">&#39;Moving average of EEGs&#39;</span>)
</code></pre></div><p><img src="../../images/eegmodelling/16.png" alt="LSTM prediction and EEGs">
Prediction errors are densest around the transition spikes, and low in between - which validates the hypotheses that they exist, and that a LSTM would remember the most recent transition until another occurs. Between transitions it has no trouble predicting, until a long anomaly occurs after t=4500. The anomaly might be close to a transition spike in the encoded state-space, hence the LSTM is slower to forget it after a transition spike does occur.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">    <span style="color:#75715e">% Plot prediction as time-series, and Confusion Matrix</span>
    [ fh1 , fh2 ] = plotPrediction( round(yfitRNNLSTM) , TargetSeq, yfitRNNLSTM , TargetSeq , <span style="color:#ae81ff">117</span><span style="color:#f92672">/</span>(N) <span style="color:#f92672">*</span>seqlen_out<span style="color:#f92672">*</span>dsr ,<span style="color:#e6db74">&#39;confusion&#39;</span> );
</code></pre></div><p><img src="../../images/eegmodelling/17.png" alt="LSTM confusion"></p>
<p>Prediction accuracy is quite high, on par with the other models. False negatives greatly outweigh false positives - mostly in the &lsquo;eyes-closed&rsquo; state between t=2500 to t=3000. As memory is passed forward through training sequences, it&rsquo;s more likely that an error will be repeated due to the nature of RNNs, rather than a section of data that was complex to learn.</p>
<h1 id="lstm-model-selection">LSTM: Model Selection</h1>
<p>Theoretically a neural network can form any nonlinear function, though practically this is unrealistic. Each dataset has hyperparmeters/ topologies that suit it uniquely. the following were varied in search for a model that would converge &amp; perform well;</p>
<ol>
<li><strong>EEG variables entered</strong>. 3 sets of varaibles EEGs: (A) 1,2,8,11,13 (B) 1,2,8,11,13 &amp; 5 (C) All 14 EEGs.</li>
<li><strong>Number of Hidden units in Encoder &amp; Decoder</strong>: To test whether the dataset was more or less complex than expected, models with 15, 30, 45 &amp; 60 Hidden units were trained.
The training performance and loss history is summarised below.</li>
</ol>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">    summariseEEGtraining(&#34;compareresults&#34;)
</code></pre></div><pre><code>         EEGs          Nunits    Accuracy    EpochsToConvergence
    _______________    ______    ________    ___________________
    &quot;1 2 8 11 13&quot;       &quot;15&quot;     &quot;72.26%&quot;          &quot;3000&quot;       
    &quot;1 2 5 8 11 13&quot;     &quot;15&quot;     &quot;66.98%&quot;          &quot;2200&quot;       
    &quot;1 2 5 8 11 13&quot;     &quot;15&quot;     &quot;94.7%&quot;           &quot;1350&quot;       
    &quot;All&quot;               &quot;15&quot;     &quot;97.63%&quot;          &quot;577&quot;        
    &quot;All&quot;               &quot;15&quot;     &quot;84.3%&quot;           &quot;850&quot;        
    &quot;1 2 8 11 13&quot;       &quot;30&quot;     &quot;69.62%&quot;          &quot;950&quot;        
    &quot;1 2 8 11 13&quot;       &quot;30&quot;     &quot;88.99%&quot;          &quot;1300&quot;       
    &quot;1 2 8 11 13&quot;       &quot;45&quot;     &quot;84.96%&quot;          &quot;1550&quot;       
    &quot;1 2 8 11 13&quot;       &quot;45&quot;     &quot;92.79%&quot;          &quot;1700&quot;       
    &quot;All&quot;               &quot;45&quot;     &quot;90.75%&quot;          &quot;1846&quot;       
    &quot;All&quot;               &quot;45&quot;     &quot;98.28%&quot;          &quot;630&quot;        
    &quot;1 2 5 8 11 13&quot;     &quot;60&quot;     &quot;98.06%&quot;          &quot;600&quot;        
    &quot;1 2 5 8 11 13&quot;     &quot;60&quot;     &quot;95.41%&quot;          &quot;960&quot;        
    &quot;All&quot;               &quot;60&quot;     &quot;98.67%&quot;          &quot;760&quot;        
</code></pre><p>Due to the stochastic nature of Neural network training, there is a lot of variation in performance. Though it seems the models with 60 Hidden units in both encoder and decoder consistently converge to a high performance in the shortest number of training epochs. In theory, more HUs smooth out the probabilistic nature of finding parameters.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">    save(<span style="color:#e6db74">&#39;EEGloseEyes_Modelling.mat&#39;</span>)
</code></pre></div><h1 id="summary">Summary</h1>
<p>The model could be an on-device predictor of eye-state to detect when the driver is having a microsleep, and trigger driverless control of the car. The business problem implied working on-line, using prior timesteps only, and a predict-ahead length of 0.2 seconds. Below in the top plot shows the longest periods each model is wrong for, in a 1-second window.</p>
<p>At worst, the PLS &amp; Lasso model is wrong for a total of 1.008 seconds, around t=12,000. These models fail the objective of the business problem.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">EEGCloseEyes_CompreModels(&#34;ModelSummaryTable&#34;)
</code></pre></div><pre><code>                           Probit     LassoProbit      PLS      RNNLSTM
                           _______    ___________    _______    _______
    Accuracy               0.94059      0.58531      0.94112    0.95234
    MaxConsecutiveError    0.60156       1.0078       1.0078     0.8125
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-matlab" data-lang="matlab">EEGCloseEyes_CompreModels(&#34;CompareModels&#34;)
</code></pre></div><p><img src="../../images/eegmodelling/18.png" alt="Model comparison"></p>
<h2 id="in-sample-performance">In-sample performance</h2>
<p>All models achieved a 90%+ test-accuracy. The LSTM-RNN achieved highest in-sample accuracy of 95.2%.</p>
<p>Concerning is the LSTMs reccuring errors during the long closed eye period in the middle of the sequence. This is a problem with RNNs that occurs because the memory (of an error) is passed forward though a single sequence input, and moreso when the memory cell is passed between batches.</p>
<h2 id="generalisation-performance">Generalisation performance</h2>
<p>Generalisation performance could have been checked by holding a set of consecutive observations out before training, though the business application would be for use by different users to test data, so evauluating generalisation performance would be both wrong and irresponsible.</p>
<p>When in doubt, the simpler model is preffered. The LSTM used only 6 input variables, where the Lasso, Probit and PLS models were fed 91 correlation variables. 91 is likely too many for the size of the sample to be reliable. Speculating, the LSTM is the superior model.</p>
<h2 id="real-world-application-of-predictions">Real-world application of predictions</h2>
<p>Within a 1 second prediction period, Probit model had a maximum of 0.4 seconds of error, PLS &amp; Lasso-probit had 0.6 seconds. The LSTM has a 1 second window with 0.634 seconds of error.</p>
<p>Best model in training was LSTM. Though, for real-world application, more info is needed: on the hardware limitations &amp; the specifics of how user interacts with the product. For example limited computational power / memory might restric use of LSTM neural network. In Probit, Lasso &amp; PLS, Perhaps the correlation data is overfitting to the sample - transition spikes were apparent across all EEGs &amp; time, so might be more genralisable to other EEG capture devices.</p>
<p>Not yet addressed is the disproportionate impact getting a Clsoed eye-state state classified as Open eyes. In the third and final section of this project, different techniques will be used to tune the models to minimise this impact.</p>
<hr>
<p><em>In the next volume of this project, the cost imbalance of misclassification is addressed</em></p>
		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="https://github.com/samoliverschumacher/tags/timeseries/" rel="tag">timeseries</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="https://github.com/samoliverschumacher/tags/classification/" rel="tag">classification</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="https://github.com/samoliverschumacher/tags/feature-engineering/" rel="tag">feature engineering</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="https://github.com/samoliverschumacher/tags/lstm/" rel="tag">LSTM</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="https://github.com/samoliverschumacher/tags/neural-network/" rel="tag">neural network</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="https://github.com/samoliverschumacher/tags/lasso/" rel="tag">lasso</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="https://github.com/samoliverschumacher/tags/exploratory-data-analysis/" rel="tag">exploratory data analysis</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<figure class="authorbox__avatar">
		<img alt="Sam Schumacher avatar" src="https://github.com/samoliverschumacher/images/eegeda/2.png" class="avatar" height="90" width="90">
	</figure>
	<div class="authorbox__header">
		<span class="authorbox__name">About Sam Schumacher</span>
	</div>
	<div class="authorbox__description">
		Using machine learning projects to discover the world through its problems
	</div>
</div>

<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="https://github.com/samoliverschumacher/post/eeg_costtradeoff/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Autonomous vechicle microsleep detector Vol3: Misclassification tradeoff</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="https://github.com/samoliverschumacher/post/eeg_eda/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Autonomous vechicle microsleep detector Vol1: EDA</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 Sam Schumacher.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>

<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
	</div>
<script async defer src="https://github.com/samoliverschumacher/js/menu.js"></script>
</body>
</html>